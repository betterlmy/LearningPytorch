{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 卷积操作和卷积层的定义"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[19., 25.],\n        [37., 43.]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import d2l\n",
    "\n",
    "\n",
    "def corr2d(X, K):\n",
    "    \"\"\"\n",
    "    计算二维互相关运算\n",
    "    :param X: 要计算的图像\n",
    "    :param K: 卷积核\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    height, width = K.shape\n",
    "    new_size = (X.shape[0] - height + 1, X.shape[1] - width + 1)\n",
    "    Y = torch.zeros(new_size)\n",
    "    for i in range(new_size[0]):\n",
    "        for j in range(new_size[1]):\n",
    "            Y[i, j] = (X[i:i + height, j:j + width] * K).sum()\n",
    "    return Y\n",
    "\n",
    "\n",
    "X = torch.tensor([\n",
    "    [0.0, 1.0, 2.0],\n",
    "    [3.0, 4.0, 5.0],\n",
    "    [6.0, 7.0, 8.0]\n",
    "])\n",
    "kernel = torch.tensor([\n",
    "    [0.0, 1.0],\n",
    "    [2.0, 3.0]\n",
    "])\n",
    "\n",
    "corr2d(X, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Conv2d(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"计算卷积的操作\"\"\"\n",
    "        return corr2d(x, self.weight) + self.bias"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 利用1*2卷积核对图像进行边缘检测"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用X模拟图像\n",
    "\n",
    "构造卷积核 高度为1 宽度为2 !!!注意 卷积核一定是tensor 而非向量\n",
    "进行互运算 如果两个元素相同 输出为0，否则输出1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n         [1., 1., 1., 1., 1., 1., 1., 1.],\n         [0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0.],\n         [1., 1., 1., 1., 1., 1., 1., 1.],\n         [1., 1., 1., 1., 1., 1., 1., 1.]]),\n tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n         [1., 1., 1., 1., 1., 1., 1., 1.],\n         [0., 0., 0., 0., 0., 0., 0., 0.],\n         [1., 1., 1., 1., 1., 1., 1., 1.],\n         [0., 0., 0., 0., 0., 0., 0., 0.]]))"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((6, 8))\n",
    "Y = torch.tensor([[1.0, -1.0]])\n",
    "# X[:, 2:6] = 0\n",
    "# K_vert = torch.tensor([[1.0, -1.0]])  # 这里的卷积核只可以判断垂直边缘\n",
    "\n",
    "X[2:4, :] = 0\n",
    "K_horiz = torch.tensor([[1.0],\n",
    "                        [-1.0]])  # 这里的卷积核只可以判断水平边缘\n",
    "result = corr2d(X, K_horiz).abs()\n",
    "X, result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "[(1, 0),\n (1, 1),\n (1, 2),\n (1, 3),\n (1, 4),\n (1, 5),\n (1, 6),\n (1, 7),\n (3, 0),\n (3, 1),\n (3, 2),\n (3, 3),\n (3, 4),\n (3, 5),\n (3, 6),\n (3, 7)]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge = []\n",
    "for i in range(result.shape[0]):\n",
    "    for j in range(result.shape[1]):\n",
    "        if result[i, j] == 1.0:\n",
    "            edge.append((i, j))\n",
    "edge"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 学习卷积核"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch2,loss=0.835\n",
      "epoch4,loss=0.185\n",
      "epoch6,loss=0.050\n",
      "epoch8,loss=0.016\n",
      "epoch10,loss=0.006\n"
     ]
    }
   ],
   "source": [
    "# 构造一个卷积层， 输出和输出都是单通道 ，形状为1*2\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(1, 2), bias=False)\n",
    "\n",
    "X = torch.ones((6, 8))\n",
    "K = torch.tensor([[1.0, -1.0]])\n",
    "X[:, 2:6] = 0\n",
    "Y = corr2d(X, K)\n",
    "# 二维的卷积层使用四维的输入和输出格式，（批量大小，通道，高度，宽度）\n",
    "X = X.reshape((1, 1, 6, 8))\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "\n",
    "lr = 3e-2\n",
    "\n",
    "for i in range(10):\n",
    "    Y_hat = conv2d(X)\n",
    "    loss = (Y - Y_hat) ** 2\n",
    "    conv2d.zero_grad()\n",
    "    loss.sum().backward()\n",
    "    # 迭代卷积核\n",
    "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(f'epoch{i + 1},loss={loss.sum():.3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 1.0033, -0.9883]]]])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 多通道计算"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 多通道输入单通道输出"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 56.,  72.],\n        [104., 120.]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import lmy\n",
    "\n",
    "\n",
    "def corr2d_multi_in(X, K):\n",
    "    return sum(lmy.corr2d(x, k) for x, k in zip(X, K))\n",
    "\n",
    "\n",
    "X = torch.Tensor([\n",
    "    [\n",
    "        [0.0, 1.0, 2.0],\n",
    "        [3.0, 4.0, 5.0],\n",
    "        [6.0, 7.0, 8.0]\n",
    "    ],\n",
    "    [\n",
    "        [1.0, 2.0, 3.0],\n",
    "        [4.0, 5.0, 6.0],\n",
    "        [7.0, 8.0, 9.0]\n",
    "    ]\n",
    "])\n",
    "KER = torch.Tensor([\n",
    "    [\n",
    "        [0.0, 1.0],\n",
    "        [2.0, 3.0]\n",
    "    ],\n",
    "    [\n",
    "        [1.0, 2.0],\n",
    "        [3.0, 4.0]\n",
    "    ]\n",
    "])\n",
    "corr2d_multi_in(X, KER)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 多输出通道"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| tmp: [tensor([[ 56.,  72.],\n",
      "                 [104., 120.]]),\n",
      "          tensor([[ 76., 100.],\n",
      "                 [148., 172.]]),\n",
      "          tensor([[ 96., 128.],\n",
      "                 [192., 224.]])]\n"
     ]
    },
    {
     "data": {
      "text/plain": "(torch.Size([2, 2, 2]),\n torch.Size([3, 2, 2, 2]),\n tensor([[[ 56.,  72.],\n          [104., 120.]],\n \n         [[ 76., 100.],\n          [148., 172.]],\n \n         [[ 96., 128.],\n          [192., 224.]]]))"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from icecream import ic\n",
    "\n",
    "\n",
    "def corr2d_multi_in_out(X, K):\n",
    "    # 迭代K的第\n",
    "    tmp = [corr2d_multi_in(X, k) for k in K]\n",
    "    ic(tmp)\n",
    "    return torch.stack(tmp, 0)\n",
    "\n",
    "\n",
    "K = torch.Tensor([\n",
    "    [\n",
    "        [0.0, 1.0],\n",
    "        [2.0, 3.0]\n",
    "    ],\n",
    "    [\n",
    "        [1.0, 2.0],\n",
    "        [3.0, 4.0]\n",
    "    ]\n",
    "])\n",
    "K1 = torch.stack((K, K + 1, K + 2), 0)\n",
    "K.shape, K1.shape, corr2d_multi_in_out(X, K1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1X1卷积层\n",
    "* 不能够提取相邻像素的相关特征\n",
    "* 经常包含在复杂深层的网络设计中\n",
    "* 唯一的计算发生在通道上\n",
    "* 用来调整网络层的通道数和控制模型复杂度"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    print(X)\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    print(X)\n",
    "    print(K)\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    print(K)\n",
    "    Y = torch.mm(K, X)\n",
    "    return Y.reshape((c_o, h, w))\n",
    "\n",
    "\n",
    "X = torch.normal(0, 1, (3, 3, 3))\n",
    "K = torch.normal(0, 1, (2, 3, 1, 1))\n",
    "corr2d_multi_in_out_1x1(X, K)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 汇聚层 Pooling Layer\n",
    "* 降低卷积层对位置的敏感性\n",
    "* 降低对空间降采样表示的敏感性"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "处理图像时，我们希望逐渐降低隐藏表示的空间分辨率，聚集信息，这样随着我们在神经网络中层叠的上升，每个神经元对其敏感的感受野（输入）就越大，\n",
    "而机器学习任务通常会跟全局图像问题有关（图片中有猫？） 所以我们最后一层的神经元应该对整个输入有全局敏感，通过逐渐聚合信息，生成越来越粗糙的映射，最终实现学习全局表示的目标，同时将卷积图层的所有优势保留在中间层"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 最大汇聚层和平均汇聚层\n",
    "与卷积层类似，汇聚层运算符由一个固定形状的窗口组成，该窗口根据其步幅大小在输入的所有区域上滑动，为固定形状窗口（汇聚窗口）遍历每个位置计算一个输出。\n",
    "But，different with the cross correlation calculation between the input of convolution layer and the kernel of the convolution,pooling layer has no parameters.On the contrary,**Pool Operation is definite**, we always calculate the maximum or mean of the items in the pooling window.These operations named **maximum pooling(最大汇聚层**） and **mean pooling（平均汇聚层）**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![image-20220406180512205](md.assets/image-20220406180512205.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "下面的pool2d函数，实现汇聚层的前向传播"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[4., 5.],\n         [7., 8.]]),\n tensor([[2., 3.],\n         [5., 6.]]))"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def pool2d(X, pool_size, mode='max'):\n",
    "    pool_height, pool_width = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - pool_height + 1, X.shape[1] - pool_width + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i:i + pool_height, j:j + pool_width].max()\n",
    "            elif mode == \"mean\":\n",
    "                Y[i, j] = X[i:i + pool_height, j:j + pool_width].mean()\n",
    "            else:\n",
    "                print(\"modeError\")\n",
    "                return None\n",
    "    return Y\n",
    "\n",
    "\n",
    "X = torch.tensor([\n",
    "    [0.0, 1.0, 2.0],\n",
    "    [3.0, 4.0, 5.0],\n",
    "    [6.0, 7.0, 8.0]\n",
    "])\n",
    "pool2d(X, (2, 2)),pool2d(X, (2, 2),mode='mean')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 填充与步幅"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]]]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "在默认情况下，torch中的步幅与汇聚窗口的大小相同，因此，如果我们使用3X3的窗口，默认stride=3X3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[[[10.]]]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d((3, 3))\n",
    "pool2d(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 6.,  7.],\n          [10., 11.],\n          [14., 15.]]]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d((2, 3),stride=1,padding=0)\n",
    "pool2d(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pooling 多通道\n",
    "在处理多通道输入数据时，汇聚层在每个输入通道上单独运算，而不是像卷积层一样在通道上对输入进行汇总。 这意味着汇聚层的输出通道数与输入通道数相同。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]],\n\n         [[ 1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.],\n          [ 9., 10., 11., 12.],\n          [13., 14., 15., 16.]]]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.cat((X, X + 1), dim=1)\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 5.,  7.],\n          [13., 15.]],\n\n         [[ 6.,  8.],\n          [14., 16.]]]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}