{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Torch参数管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zane/miniforge3/envs/torch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[0.2496],\n        [0.1374]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
    "X = torch.randn((2,4))\n",
    "net(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 参数访问"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=4, out_features=8, bias=True)*****OrderedDict([('weight', tensor([[-0.2865,  0.1825,  0.4246,  0.0404],\n",
      "        [-0.1624,  0.2773,  0.3223,  0.4330],\n",
      "        [ 0.2916,  0.4496, -0.1923, -0.1654],\n",
      "        [ 0.1439,  0.4049,  0.1987,  0.4646],\n",
      "        [ 0.1551,  0.0485, -0.0547,  0.3895],\n",
      "        [-0.0592, -0.2092,  0.3625,  0.4155],\n",
      "        [ 0.4247, -0.4286, -0.0481,  0.0708],\n",
      "        [ 0.4779, -0.1641, -0.4195,  0.2046]])), ('bias', tensor([-0.2723, -0.0415, -0.0759, -0.3348,  0.3937, -0.4272,  0.2256, -0.2450]))])\n",
      "ReLU()*****OrderedDict()\n",
      "Linear(in_features=8, out_features=1, bias=True)*****OrderedDict([('weight', tensor([[ 0.0411, -0.2077,  0.3242, -0.1308, -0.0301, -0.1770,  0.2029,  0.0360]])), ('bias', tensor([0.1242]))])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(net)):\n",
    "    print(net[i],end=\"*****\")\n",
    "    print(net[i].state_dict())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 获取单个参数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.1242], requires_grad=True)\n",
      "tensor([0.1242])\n"
     ]
    }
   ],
   "source": [
    "print(net[2].bias)\n",
    "print(net[2].bias.data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 遍历所有的参数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
     ]
    }
   ],
   "source": [
    "print(*[(name,param.shape) for name,param in net[0].named_parameters()])\n",
    "print(*[(name,param.shape) for name,param in net.named_parameters()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 从嵌套块收集参数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| rgnet: Sequential(\n",
      "             (0): Sequential(\n",
      "               (block0): Sequential(\n",
      "                 (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "                 (1): ReLU()\n",
      "                 (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "                 (3): ReLU()\n",
      "               )\n",
      "               (block1): Sequential(\n",
      "                 (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "                 (1): ReLU()\n",
      "                 (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "                 (3): ReLU()\n",
      "               )\n",
      "               (block2): Sequential(\n",
      "                 (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "                 (1): ReLU()\n",
      "                 (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "                 (3): ReLU()\n",
      "               )\n",
      "               (block3): Sequential(\n",
      "                 (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "                 (1): ReLU()\n",
      "                 (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "                 (3): ReLU()\n",
      "               )\n",
      "             )\n",
      "             (1): Linear(in_features=4, out_features=1, bias=True)\n",
      "           )\n",
      "ic| rgnet[0]: Sequential(\n",
      "                (block0): Sequential(\n",
      "                  (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "                  (1): ReLU()\n",
      "                  (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "                  (3): ReLU()\n",
      "                )\n",
      "                (block1): Sequential(\n",
      "                  (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "                  (1): ReLU()\n",
      "                  (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "                  (3): ReLU()\n",
      "                )\n",
      "                (block2): Sequential(\n",
      "                  (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "                  (1): ReLU()\n",
      "                  (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "                  (3): ReLU()\n",
      "                )\n",
      "                (block3): Sequential(\n",
      "                  (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "                  (1): ReLU()\n",
      "                  (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "                  (3): ReLU()\n",
      "                )\n",
      "              )\n",
      "ic| rgnet[0][0]: Sequential(\n",
      "                   (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "                   (1): ReLU()\n",
      "                   (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "                   (3): ReLU()\n",
      "                 )\n",
      "ic| rgnet[0][0][0]: Linear(in_features=4, out_features=8, bias=True)\n",
      "ic| rgnet[0][0][0].bias.data: tensor([ 0.3426,  0.0028,  0.2502,  0.0514, -0.2991,  0.1288,  0.0073, -0.1657])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([ 0.3426,  0.0028,  0.2502,  0.0514, -0.2991,  0.1288,  0.0073, -0.1657])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from icecream import ic\n",
    "\n",
    "\n",
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
    "                         nn.Linear(8, 4), nn.ReLU())\n",
    "\n",
    "\n",
    "def block2(n):\n",
    "    net = nn.Sequential()\n",
    "    for i in range(n):\n",
    "        # 嵌套在这里\n",
    "        net.add_module(name=f\"block{i}\", module=block1())\n",
    "    return net\n",
    "\n",
    "\n",
    "rgnet = nn.Sequential(block2(4), nn.Linear(4, 1))\n",
    "ic(rgnet)\n",
    "ic(rgnet[0])\n",
    "ic(rgnet[0][0])\n",
    "ic(rgnet[0][0][0])\n",
    "ic(rgnet[0][0][0].bias.data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 参数初始化\n",
    "Torch内置的参数初始化为随机初始化，但也允许我们自定义初始化方法 nn.init模块中提供了多种初始化方法"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 内置初始化"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): Sequential(\n    (block0): Sequential(\n      (0): Linear(in_features=4, out_features=8, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=8, out_features=4, bias=True)\n      (3): ReLU()\n    )\n    (block1): Sequential(\n      (0): Linear(in_features=4, out_features=8, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=8, out_features=4, bias=True)\n      (3): ReLU()\n    )\n    (block2): Sequential(\n      (0): Linear(in_features=4, out_features=8, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=8, out_features=4, bias=True)\n      (3): ReLU()\n    )\n    (block3): Sequential(\n      (0): Linear(in_features=4, out_features=8, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=8, out_features=4, bias=True)\n      (3): ReLU()\n    )\n  )\n  (1): Linear(in_features=4, out_features=1, bias=True)\n)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_normal(module):\n",
    "    \"\"\"\n",
    "    权重初始化为高斯分布\n",
    "    偏置置0\n",
    "    :param module:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if type(module)==nn.Module:\n",
    "        nn.init.normal_(tensor=module.weight,mean=0,std=.01)\n",
    "        nn.init.zeros_(tensor=module.bias)\n",
    "\n",
    "def init_const(module):\n",
    "    if type(module)==nn.Module:\n",
    "        nn.init.constant(module.weight,1)\n",
    "        nn.init.zeros_(tensor=module.bias)\n",
    "\n",
    "rgnet.apply(init_normal)\n",
    "# print(rgnet.weight.data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}