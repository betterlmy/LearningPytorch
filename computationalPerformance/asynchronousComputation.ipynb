{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Python is not a great way to writing parallel and asynchronous code.\n",
    "Understanding how asynchronous programming works help us tp develop more efficient programs,by proactively reducing computational requirements and mutual dependencies.This allows us to reduce memory overhead and increase processor utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import lmy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Asynchrony via backend"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comparison of numpy and pytorch with matrix multiplication"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Timer  has run for 2.5340s\n",
      "torch Timer  has run for 0.4122s\n",
      "torch Timer  has run for 0.4085s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "numpyTimer = lmy.Timer('Numpy Timer')\n",
    "torchTimer = lmy.Timer('torch Timer')\n",
    "with numpyTimer:\n",
    "    for i in range(30):\n",
    "        a = np.random.normal(size=(1000, 1000))\n",
    "        b = a @ a\n",
    "\n",
    "devices, _ = lmy.getGPU()\n",
    "device = devices[0]\n",
    "with torchTimer:\n",
    "    for i in range(30):\n",
    "        a = torch.randn((1000, 1000), device=device)\n",
    "        b = torch.mm(a, a)\n",
    "\n",
    "with torchTimer:\n",
    "    for i in range(30):\n",
    "        a = torch.randn((1000, 1000), device=device)\n",
    "        b = torch.mm(a, a)\n",
    "    if 'cuda' in device.type:\n",
    "        torch.cuda.synchronize(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}