{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## GAN\n",
    "全称Generative Adversarial Networks,即生成-对抗网络，是一种NN 模型，是建立在复杂分布数据的基础上的无监督学习方。\n",
    "GAN中有两大模块，第一模块Model是生成模型（Generative Model,G）第二个模块是判别模型（对抗模型，Discriminative Model D）。\n",
    "GAN的学习便是两个模块的博弈对抗。 在GAN的理论中，并不要求G和D都是神经网络，只要是能拟合相应生成和判别的函数即可。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GAN的内部定义\n",
    "数据方面：我们有真实的数据，例如图片，还有自定义的噪声，将噪声数据输入到G中，G对噪声进行编码处理，从低维到高维，最终生成一张图片，最后将噪声与真实的图片给D，D进行判别处理，最后对结果进行优化。\n",
    "我们需要明确一点**G和D是分开训练的**。两者在训练的过程中分别进步，一开始初始化G和D中的权重，此时G和D只是几层网络而已，下面通过向G输入噪声，G此时生成的数据毫无实际意义，可能是乱码或者其他未知的图片，之后，通过人工操作，将数据输入到D中，我们自己让D对这些数据判别为False，之后输入真实的图片，手动使D判别为True，之后对D和G的参数进行优化，优化的目标是以真实图片训练参数，进行n次训练后，参数偏向稳定状态，此时我们如果输入随机数到G中，G便会生成图片，且D会自行将生成的图片判断为True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GAN的Torch实现"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zane/miniforge3/envs/torch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('../d2l.py')\n",
    "import lmy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "创建图片所在的文件夹"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "if not os.path.exists('./img'):\n",
    "    os.mkdir('./img')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    \"\"\"将tensor转为图片格式\"\"\"\n",
    "    x = (x + 1) * .5\n",
    "    x = x.clamp(0, 1) # clamp 夹紧，将x的值限制在0-1之间\n",
    "    x = x.view(-1, 1, 28, 28) #view()函数的作用，将多行的tensor转换为多个二维的图片\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils import data\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = 100\n",
    "z_dimension = 100\n",
    "# 图像预处理\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将图像转换为tensor\n",
    "    transforms.Normalize([0.5], [0.5])  # 归一化\n",
    "])\n",
    "# 读取数据\n",
    "mnist_train = FashionMNIST(root='../lmy/data', train=True, transform=img_transform, download=False)\n",
    "bags_data = []\n",
    "for i, (img, label) in enumerate(mnist_train):\n",
    "    if label == 8:\n",
    "        bags_data.append(img)\n",
    "train_iter = data.DataLoader(bags_data, batch_size, shuffle=False, num_workers=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "定义判别器D网络"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(784, 256), nn.LeakyReLU(.2),\n",
    "            nn.Linear(256, 256), nn.LeakyReLU(.2),\n",
    "            nn.Linear(256, 1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.discriminator(x)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generator = nn.Sequential(\n",
    "            nn.Linear(100, 256),  # 用线性变换将输入映射到256维 输入是100维\n",
    "            nn.ReLU(),  # relu激活\n",
    "            nn.Linear(256, 256),  # 线性变换\n",
    "            nn.ReLU(),  # relu激活\n",
    "            nn.Linear(256, 784),  # 线性变换\n",
    "            nn.Tanh()  # Tanh激活使得生成数据分布在【-1,1】之间，因为输入的真实数据的经过transforms之后也是这个分布\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.generator(x)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "实例化网络"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "D = Discriminator()\n",
    "G = Generator()\n",
    "devices = lmy.getGPU(contain_cpu=True)\n",
    "cuda_available = False\n",
    "if 'cuda' in devices[0].type:\n",
    "    cuda_available = True\n",
    "\n",
    "if cuda_available:\n",
    "    D = D.to(devices[0])\n",
    "    G = G.to(devices[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "评价标准和优化器"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss() # 二进制交叉熵 因为结果只有True和False\n",
    "g_optimizer = torch.optim.Adam(G.parameters(),lr=.001)\n",
    "d_optimizer = torch.optim.Adam(D.parameters(),lr=.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x11b4858b0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/zane/miniforge3/envs/torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/zane/miniforge3/envs/torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/100],d_loss:0.000001,g_loss:14.658181 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[0/100],d_loss:0.000002,g_loss:14.747150 ,D real: 1.000000,D fake: 0.000002\n",
      "Epoch[1/100],d_loss:0.000001,g_loss:14.753455 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[1/100],d_loss:0.000001,g_loss:14.400969 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[2/100],d_loss:0.000001,g_loss:14.398615 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[2/100],d_loss:0.000001,g_loss:14.841447 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[3/100],d_loss:0.000001,g_loss:14.792832 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[3/100],d_loss:0.000001,g_loss:14.731848 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[4/100],d_loss:0.000001,g_loss:14.868746 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[4/100],d_loss:0.000001,g_loss:14.528069 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[5/100],d_loss:0.000001,g_loss:14.464863 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[5/100],d_loss:0.000001,g_loss:14.584456 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[6/100],d_loss:0.000001,g_loss:14.664496 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[6/100],d_loss:0.000001,g_loss:14.780423 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[7/100],d_loss:0.000001,g_loss:14.839876 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[7/100],d_loss:0.000001,g_loss:14.608283 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[8/100],d_loss:0.000001,g_loss:14.834793 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[8/100],d_loss:0.000001,g_loss:14.763879 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[9/100],d_loss:0.000001,g_loss:14.714403 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[9/100],d_loss:0.000001,g_loss:14.706497 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[10/100],d_loss:0.000001,g_loss:14.814355 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[10/100],d_loss:0.000001,g_loss:14.825958 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[11/100],d_loss:0.000001,g_loss:14.797101 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[11/100],d_loss:0.000001,g_loss:14.788456 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[12/100],d_loss:0.000001,g_loss:15.212667 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[12/100],d_loss:0.000001,g_loss:14.698761 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[13/100],d_loss:0.000001,g_loss:14.718931 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[13/100],d_loss:0.000001,g_loss:14.947886 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[14/100],d_loss:0.000001,g_loss:15.232631 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[14/100],d_loss:0.000001,g_loss:14.964815 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[15/100],d_loss:0.000001,g_loss:14.794887 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[15/100],d_loss:0.000001,g_loss:14.936451 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[16/100],d_loss:0.000001,g_loss:14.743699 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[16/100],d_loss:0.000001,g_loss:15.011095 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[17/100],d_loss:0.000001,g_loss:15.035759 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[17/100],d_loss:0.000001,g_loss:15.338039 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[18/100],d_loss:0.000001,g_loss:15.052979 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[18/100],d_loss:0.000001,g_loss:15.166415 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[19/100],d_loss:0.000001,g_loss:15.115819 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[19/100],d_loss:0.000001,g_loss:14.884024 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[20/100],d_loss:0.000001,g_loss:14.860723 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[20/100],d_loss:0.000001,g_loss:14.868335 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[21/100],d_loss:0.000001,g_loss:14.854052 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[21/100],d_loss:0.000001,g_loss:14.987770 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[22/100],d_loss:0.000001,g_loss:15.220383 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[22/100],d_loss:0.000001,g_loss:14.987731 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[23/100],d_loss:0.000001,g_loss:15.113557 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[23/100],d_loss:0.000001,g_loss:15.222092 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[24/100],d_loss:0.000001,g_loss:15.434954 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[24/100],d_loss:0.000001,g_loss:15.228098 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[25/100],d_loss:0.000001,g_loss:15.206067 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[25/100],d_loss:0.000001,g_loss:15.537634 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[26/100],d_loss:0.000001,g_loss:15.183239 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[26/100],d_loss:0.000001,g_loss:15.371699 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[27/100],d_loss:0.000001,g_loss:15.052283 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[27/100],d_loss:0.000001,g_loss:15.449296 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[28/100],d_loss:0.000001,g_loss:15.055237 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[28/100],d_loss:0.000001,g_loss:15.407650 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[29/100],d_loss:0.000001,g_loss:15.481132 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[29/100],d_loss:0.000001,g_loss:15.099960 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[30/100],d_loss:0.000001,g_loss:15.330866 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[30/100],d_loss:0.000001,g_loss:15.290823 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[31/100],d_loss:0.000001,g_loss:15.503745 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[31/100],d_loss:0.000001,g_loss:15.350118 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[32/100],d_loss:0.000001,g_loss:15.197035 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[32/100],d_loss:0.000001,g_loss:15.287802 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[33/100],d_loss:0.000000,g_loss:15.534720 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[33/100],d_loss:0.000001,g_loss:15.651089 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[34/100],d_loss:0.000001,g_loss:15.493492 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[34/100],d_loss:0.000001,g_loss:15.512499 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[35/100],d_loss:0.000000,g_loss:15.521206 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[35/100],d_loss:0.000001,g_loss:15.233206 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[36/100],d_loss:0.000001,g_loss:15.670978 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[36/100],d_loss:0.000000,g_loss:15.520054 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[37/100],d_loss:0.000001,g_loss:15.286453 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[37/100],d_loss:0.000001,g_loss:15.603552 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[38/100],d_loss:0.000001,g_loss:15.629218 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[38/100],d_loss:0.000001,g_loss:15.708697 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[39/100],d_loss:0.000001,g_loss:15.390928 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[39/100],d_loss:0.000001,g_loss:15.828899 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[40/100],d_loss:0.000001,g_loss:15.709501 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[40/100],d_loss:0.000001,g_loss:15.460755 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[41/100],d_loss:0.000000,g_loss:15.670552 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[41/100],d_loss:0.000001,g_loss:15.732763 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[42/100],d_loss:0.000001,g_loss:15.759646 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[42/100],d_loss:0.000000,g_loss:15.648100 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[43/100],d_loss:0.000001,g_loss:15.930036 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[43/100],d_loss:0.000001,g_loss:15.971417 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[44/100],d_loss:0.000000,g_loss:15.753645 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[44/100],d_loss:0.000000,g_loss:15.955519 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[45/100],d_loss:0.000000,g_loss:15.849198 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[45/100],d_loss:0.000000,g_loss:15.527518 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[46/100],d_loss:0.000000,g_loss:15.639654 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[46/100],d_loss:0.000000,g_loss:16.061413 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[47/100],d_loss:0.000000,g_loss:15.922940 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[47/100],d_loss:0.000000,g_loss:15.922073 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[48/100],d_loss:0.000000,g_loss:15.967072 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[48/100],d_loss:0.000001,g_loss:15.881994 ,D real: 1.000000,D fake: 0.000001\n",
      "Epoch[49/100],d_loss:0.000000,g_loss:16.289053 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[49/100],d_loss:0.000000,g_loss:15.737496 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[50/100],d_loss:0.000000,g_loss:15.987301 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[50/100],d_loss:0.000000,g_loss:15.955860 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[51/100],d_loss:0.000000,g_loss:15.712865 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[51/100],d_loss:0.000000,g_loss:15.920551 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[52/100],d_loss:0.000000,g_loss:15.971736 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[52/100],d_loss:0.000000,g_loss:15.970693 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[53/100],d_loss:0.000000,g_loss:16.137772 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[53/100],d_loss:0.000000,g_loss:16.039042 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[54/100],d_loss:0.000000,g_loss:16.216425 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[54/100],d_loss:0.000000,g_loss:16.040222 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[55/100],d_loss:0.000000,g_loss:16.210436 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[55/100],d_loss:0.000000,g_loss:16.096107 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[56/100],d_loss:0.000000,g_loss:16.100418 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[56/100],d_loss:0.000000,g_loss:16.265406 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[57/100],d_loss:0.000000,g_loss:16.149416 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[57/100],d_loss:0.000000,g_loss:16.114246 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[58/100],d_loss:0.000000,g_loss:16.347792 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[58/100],d_loss:0.000000,g_loss:16.156141 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[59/100],d_loss:0.000000,g_loss:16.197216 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[59/100],d_loss:0.000000,g_loss:16.310572 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[60/100],d_loss:0.000000,g_loss:16.269804 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[60/100],d_loss:0.000000,g_loss:16.186033 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[61/100],d_loss:0.000000,g_loss:16.357601 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[61/100],d_loss:0.000000,g_loss:16.327042 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[62/100],d_loss:0.000000,g_loss:16.452286 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[62/100],d_loss:0.000000,g_loss:16.215271 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[63/100],d_loss:0.000000,g_loss:16.259861 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[63/100],d_loss:0.000000,g_loss:16.176086 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[64/100],d_loss:0.000000,g_loss:16.428516 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[64/100],d_loss:0.000000,g_loss:16.240223 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[65/100],d_loss:0.000000,g_loss:16.371565 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[65/100],d_loss:0.000000,g_loss:16.295017 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[66/100],d_loss:0.000000,g_loss:16.262960 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[66/100],d_loss:0.000000,g_loss:16.032372 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[67/100],d_loss:0.000000,g_loss:16.478582 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[67/100],d_loss:0.000000,g_loss:16.292828 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[68/100],d_loss:0.000000,g_loss:16.739510 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[68/100],d_loss:0.000000,g_loss:16.400650 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[69/100],d_loss:0.000000,g_loss:16.376158 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[69/100],d_loss:0.000000,g_loss:16.356138 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[70/100],d_loss:0.000000,g_loss:16.519028 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[70/100],d_loss:0.000000,g_loss:16.443588 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[71/100],d_loss:0.000000,g_loss:16.804579 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[71/100],d_loss:0.000000,g_loss:16.739613 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[72/100],d_loss:0.000000,g_loss:16.704342 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[72/100],d_loss:0.000000,g_loss:16.572393 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[73/100],d_loss:0.000000,g_loss:16.738604 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[73/100],d_loss:0.000000,g_loss:16.733465 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[74/100],d_loss:0.000000,g_loss:16.412338 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[74/100],d_loss:0.000000,g_loss:16.637709 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[75/100],d_loss:0.000000,g_loss:16.757393 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[75/100],d_loss:0.000000,g_loss:16.605412 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[76/100],d_loss:0.000000,g_loss:16.587107 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[76/100],d_loss:0.000000,g_loss:16.754906 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[77/100],d_loss:0.000000,g_loss:17.058907 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[77/100],d_loss:0.000000,g_loss:16.664579 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[78/100],d_loss:0.000000,g_loss:16.848898 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[78/100],d_loss:0.000000,g_loss:16.741852 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[79/100],d_loss:0.000000,g_loss:16.887503 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[79/100],d_loss:0.000000,g_loss:16.901093 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[80/100],d_loss:0.000000,g_loss:16.995165 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[80/100],d_loss:0.000000,g_loss:16.937874 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[81/100],d_loss:0.000000,g_loss:16.559628 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[81/100],d_loss:0.000000,g_loss:17.445072 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[82/100],d_loss:0.000000,g_loss:17.029234 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[82/100],d_loss:0.000000,g_loss:16.930456 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[83/100],d_loss:0.000000,g_loss:16.807512 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[83/100],d_loss:0.000000,g_loss:17.028137 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[84/100],d_loss:0.000000,g_loss:17.188282 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[84/100],d_loss:0.000000,g_loss:17.184658 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[85/100],d_loss:0.000000,g_loss:17.241590 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[85/100],d_loss:0.000000,g_loss:17.218838 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[86/100],d_loss:0.000000,g_loss:17.106472 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[86/100],d_loss:0.000000,g_loss:17.020666 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[87/100],d_loss:0.000000,g_loss:17.196699 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[87/100],d_loss:0.000000,g_loss:17.073015 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[88/100],d_loss:0.000000,g_loss:17.219585 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[88/100],d_loss:0.000000,g_loss:17.170710 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[89/100],d_loss:0.000000,g_loss:17.361382 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[89/100],d_loss:0.000000,g_loss:17.332621 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[90/100],d_loss:0.000000,g_loss:17.040592 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[90/100],d_loss:0.000000,g_loss:17.131847 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[91/100],d_loss:0.000000,g_loss:17.330843 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[91/100],d_loss:0.000000,g_loss:17.383461 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[92/100],d_loss:0.000000,g_loss:17.140881 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[92/100],d_loss:0.000000,g_loss:17.328995 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[93/100],d_loss:0.000000,g_loss:17.280806 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[93/100],d_loss:0.000000,g_loss:17.439011 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[94/100],d_loss:0.000000,g_loss:17.516937 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[94/100],d_loss:0.000000,g_loss:17.012884 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[95/100],d_loss:0.000000,g_loss:17.139408 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[95/100],d_loss:0.000000,g_loss:17.442621 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[96/100],d_loss:0.000000,g_loss:17.646843 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[96/100],d_loss:0.000000,g_loss:17.385553 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[97/100],d_loss:0.000000,g_loss:17.470451 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[97/100],d_loss:0.000000,g_loss:17.307238 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[98/100],d_loss:0.000000,g_loss:17.496897 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[98/100],d_loss:0.000000,g_loss:17.403227 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[99/100],d_loss:0.000000,g_loss:17.348234 ,D real: 1.000000,D fake: 0.000000\n",
      "Epoch[99/100],d_loss:0.000000,g_loss:17.655560 ,D real: 1.000000,D fake: 0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, train_imgs in enumerate(train_iter):\n",
    "        num_imgs = len(train_imgs)  # = batch_size\n",
    "        #====================训练判别器D==================#\n",
    "        # 判别器的训练分为两个部分：1 真实图像判别为真 2 生成图像判别为假\n",
    "\n",
    "        train_imgs = train_imgs.reshape(num_imgs, -1)  # 拉平 将一个batch所有的图片放到一个tensor中\n",
    "        # print(train_imgs.shape) # torch.Size([128, 784])\n",
    "\n",
    "        real_img = Variable(train_imgs)  #tensor转变为Vairable类型的变量\n",
    "        real_label = Variable(torch.ones(num_imgs))  # 定义真实的图片label为1\n",
    "        fake_label = Variable(torch.zeros(num_imgs))  # 定义虚假的图片label为0\n",
    "        if cuda_available:\n",
    "            real_img, real_label, fake_label = real_img.to(devices[0]), real_label.to(devices[0]), fake_label.to(\n",
    "                devices[0])\n",
    "\n",
    "        # 计算真实图片的损失\n",
    "        d_real_out = D(real_img).squeeze()  # 真实图片的输出\n",
    "        d_real_loss = criterion(d_real_out, real_label)\n",
    "        real_scores = d_real_out\n",
    "\n",
    "        # 计算假图片的损失\n",
    "        z = Variable(torch.randn(num_imgs, z_dimension))\n",
    "        if cuda_available:\n",
    "            z = z.to(devices[0])\n",
    "\n",
    "        fake_img = G(z).detach()  # 生成假图片\n",
    "        fake_out = D(fake_img).squeeze()  # 使用判别器对假图片进行判断\n",
    "        d_fake_loss = criterion(fake_out, fake_label)\n",
    "        fake_scores = fake_out\n",
    "        d_loss = d_real_loss + d_fake_loss  # 损失包括真损失和假损失\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        #====================训练生成器G==================#\n",
    "        # 目的：希望生成的假图片被判别器D判断为True\n",
    "        # 生成器的训练分两个部分：1 生成假图片 2 判别器对假图片判别为真\n",
    "        # 过程中 将判别器参数固定，将假的图片传入判别器的结果与真实的label对应\n",
    "\n",
    "        z = Variable(torch.randn(num_imgs, z_dimension))\n",
    "        if cuda_available:\n",
    "            z = z.to(devices[0])\n",
    "        fake_img = G(z).detach()\n",
    "        output = D(fake_img).squeeze()\n",
    "        g_loss = criterion(output, real_label)\n",
    "        g_optimizer.zero_grad()  # 梯度归0\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        # 打印中间的损失\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(\n",
    "                f'Epoch[{epoch}/{num_epochs}],d_loss:{d_loss.data.item():.6f},g_loss:{g_loss.data.item():.6f} ,D real: {real_scores.data.mean():.6f},D fake: {fake_scores.data.mean():.6f}')  # 打印的是真实图片的损失均值\n",
    "        if epoch == 0:\n",
    "            real_images = to_img(real_img.cpu().data)\n",
    "            torchvision.utils.save_image(real_images, './img/real_images.png')\n",
    "\n",
    "    fake_images = to_img(fake_img.cpu().data)\n",
    "    torchvision.utils.save_image(fake_images, f'./img/fake_images-{epoch + 1}.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}